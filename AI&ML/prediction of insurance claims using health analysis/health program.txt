import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import numpy as np
import sklearn.metrics



#load data
df = pd.read_csv('insurance.csv')
df = df.dropna()



#general information
df.describe()
df.corr()
df['bmi_int'] = df['bmi'].apply(lambda x: int(x))
variables = ['sex','smoker','region','age','bmi_int','children']

# data distribution analysys
print('Data distribution analysys')
for v in variables:
    df['bmi_int'] = df['bmi'].apply(lambda x: int(x))
    df[v].value_counts().plot(kind = 'bar')
    plt.title(v)
    plt.show()
#average cost analysys
print('Mean cost analysys:')
for v in variables:
    group_df = df.groupby(pd.Grouper(key=v)).mean()
    group_df = group_df.sort_index()
    group_df.plot(y = ['charges'],kind = 'pie')
    plt.show()

    #training
print('Model training and evaluating\n\n')
#Transform categorical data ,text data into numbers
le_sex = LabelEncoder()
le_smoker = LabelEncoder()
le_region = LabelEncoder()

df['sex'] = le_sex.fit_transform(df['sex'])
df['smoker'] = le_smoker.fit_transform(df['smoker'])
df['region'] = le_region.fit_transform(df['region'])

variables = ['sex','smoker','region','age','bmi','children']

X = df[variables]
sc = StandardScaler()
X = sc.fit_transform(X) 
Y = df['charges']
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)

#train model
regressor = ExtraTreesRegressor(n_estimators = 200)
regressor.fit(X_train,y_train)

#prediction and evaluation
y_train_pred = regressor.predict(X_train)
y_test_pred = regressor.predict(X_test)

print('ExtraTreesRegressor evaluating result:')
print("Train MAE: ", sklearn.metrics.mean_absolute_error(y_train, y_train_pred))
print("Train RMSE: ", np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_train_pred)))
print("Test MAE: ", sklearn.metrics.mean_absolute_error(y_test, y_test_pred))
print("Test RMSE: ", np.sqrt(sklearn.metrics.mean_squared_error(y_test, y_test_pred)))
print('Feature importance ranking\n\n')
importances = regressor.feature_importances_
std = np.std([tree.feature_importances_ for tree in regressor.estimators_],axis=0)
indices = np.argsort(importances)[::1]

importance_list = []
for f in range(X.shape[1]):
    variable = variables[indices[f]]
    importance_list.append(variable)
    print("%d.%s(%f)" % (f + 1, variable, importances[indices[f]]))

# Plot the feature importances of the forest
plt.figure()
plt.title("Feature importances")
plt.bar(importance_list, importances[indices],
       color="r", yerr=std[indices], align="center")
plt.show()
print('Predicting on new data\n\n')

austro = ['male','yes','southeast',25,30.5,2]
print('austro - ',str(austro))

austro[0] = le_sex.transform([austro[0]])[0] 
austro[1] = le_smoker.transform([austro[1]])[0] 
austro[2] = le_region.transform([austro[2]])[0] 

X = sc.transform([austro])

cost_for_austro = regressor.predict(X)[0]
print('Cost for austro = ',cost_for_austro,'\n\n')


uva = ['male','no','southeast',45,19,0]
print('uva - ',str(uva))

uva[0] = le_sex.transform([uva[0]])[0] 
uva[1] = le_smoker.transform([uva[1]])[0] 
uva[2] = le_region.transform([uva[2]])[0] 

X = sc.transform([uva])

cost_for_uva = regressor.predict(X)[0]

print('Cost for uva = ',cost_for_uva)